from xml.sax import parseString
from bs4 import BeautifulSoup
import requests
import re
import os
import pandas as pd

team_id = {'Chicago Dogs': 132636, 'Sioux Falls Canaries': 6317, 'Cleburne Railroaders': 120887, 'Gary SouthShore RailCats': 11128, 
'Kane County Cougars': 153175, 'Lake Country DockHounds': 157896, 'Milwaukee Milkmen': 141706,
'Fargo-Moorhead RedHawks': 11218, 'Kansas City Monarchs': 11129, 'Lincoln Saltdogs': 11130, 
'Sioux City Explorers': 11131, 'Winnipeg Goldeyes': 11219}
def get_pbp(game_id):
    try:
        url = "http://pointstreak.com/baseball/boxscore.html?gameid={}"
        requests_url = url.format(game_id)
        r = requests.get(requests_url)
        soup = BeautifulSoup(r.text, 'html.parser')
        table = soup.find('div', {'id': "psbb_playbyplay"})
        innings = table.find_all('table', {"class": "psbb_stats_table"})
        output_L = []
        for items in innings:
            outcome_L = items.text.split('\n')
            outcome_L = list(filter(None, outcome_L))
            for i in range(len(outcome_L)):
                outcome_L[i] = outcome_L[i].strip('\t ')
            outcome_L = list(filter(None, outcome_L))
            output_L.append(outcome_L)
        return output_L
    except:
        print("No Game Data for Game {}".format(game_id))

def populate_dict(game_data, d):
    no_swing_outcomes = ['Ball', 'Called Strike', '(hit by pitch)', '(walk)', '(strike out)']
    try:
        for inside_L in game_data:
            r = '#\d+\s{2}(.*)'
            for i in range(len(inside_L)):
                x = re.match(r, inside_L[i])
                if x!=None:
                    split_L = inside_L[i+1].split(',')
                    if inside_L[1] not in d:
                        d[inside_L[1]] = {x.group(1): {'Balls Swung': 0, 'Total Pitches Seen': 0}}
                        #for outcomes in no_swing_outcomes:
                        if no_swing_outcomes[0] not in split_L[0] and no_swing_outcomes[1] not in split_L[0] and no_swing_outcomes[2] not in split_L[0] and no_swing_outcomes[3] not in split_L[0] and no_swing_outcomes[4] not in split_L[0]:
                            d[inside_L[1]][x.group(1)]['Balls Swung']+=1
                            d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
                        else:
                            d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
                    else:
                        if x.group(1) not in d[inside_L[1]]:
                            d[inside_L[1]][x.group(1)] = {'Balls Swung': 0, 'Total Pitches Seen': 0}
                            #for outcomes in no_swing_outcomes:
                            if no_swing_outcomes[0] not in split_L[0] and no_swing_outcomes[1] not in split_L[0] and no_swing_outcomes[2] not in split_L[0] and no_swing_outcomes[3] not in split_L[0] and no_swing_outcomes[4] not in split_L[0]:
                                d[inside_L[1]][x.group(1)]['Balls Swung']+=1
                                d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
                            else:
                                d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
                        else:
                            #for outcomes in no_swing_outcomes:
                            if no_swing_outcomes[0] not in split_L[0] and no_swing_outcomes[1] not in split_L[0] and no_swing_outcomes[2] not in split_L[0] and no_swing_outcomes[3] not in split_L[0] and no_swing_outcomes[4] not in split_L[0]:
                                d[inside_L[1]][x.group(1)]['Balls Swung']+=1
                                d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
                            else:
                                d[inside_L[1]][x.group(1)]['Total Pitches Seen']+=1
    except:
        print("No Game Data")
    return d

def fps_percentage(team, d):
    output_d = {}
    for players in d[team]:
        #duplitcate name
        #if d[team][players]['Balls Swung']/d[team][players]['Total Pitches Seen']*100>0:
        output_d[players] = round(d[team][players]['Balls Swung']/d[team][players]['Total Pitches Seen']*100, 2)
    L = []
    for keys in output_d:
        L.append(keys.split())
    sorted_L = sorted(L, key = lambda x: x[1])
    for i in range(len(sorted_L)):
        sorted_L[i] = ' '.join(sorted_L[i])
    output_d_2 = {}
    for names in sorted_L:
        output_d_2[names] = output_d[names]
    return output_d_2.items()

def last_seven_avg(team):
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=last7days'
    requests_url = url.format(team_id[team])
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "battingWeekly"})
    rows = table.find_all('tr')
    output_d = {}
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        output_d[stats_L[1]] = stats_L[-2]
    return sorted(output_d.items(), key = lambda x: x[0][:3])

def get_pa(team):
    d = {}
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=batting&bset=1&orderby=avg'
    requests_url = url.format(team)
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "batting1"})
    rows = table.find_all('tr')
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        if int(stats_L[-2])>0:
            d[stats_L[1]] = int(stats_L[-2])
    return d

def walk_rate(d, team):
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=batting&bset=0&orderby=avg'
    requests_url = url.format(team)
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "batting1"})
    rows = table.find_all('tr')
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        if stats_L[1] in d:
            d[stats_L[1]] = round((int(stats_L[-10])/d[stats_L[1]])*100,1)
    output_L = []
    for keys in d:
        output_L.append(d[keys])
    return output_L

def k_rate(d, team):
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=batting&bset=0&orderby=avg'
    requests_url = url.format(team)
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "batting1"})
    rows = table.find_all('tr')
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        if stats_L[1] in d:
            d[stats_L[1]] = round((int(stats_L[-8])/d[stats_L[1]])*100,1)
    output_L = []
    for keys in d:
        output_L.append(d[keys])
    return output_L

def iso(d, team):
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=batting&bset=2&orderby=avg'
    requests_url = url.format(team)
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "batting1"})
    rows = table.find_all('tr')
    output_L = []
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        if stats_L[1] in d:
            output_L.append(stats_L[-3])
    return output_L


def get_names_in_average(team):
    url = 'http://pointstreak.com/baseball/team_stats.html?teamid={}&seasonid=33290&view=batting&bset=0&orderby=avg'
    requests_url = url.format(team)
    r = requests.get(requests_url)
    soup = BeautifulSoup(r.text, 'html.parser')
    table = soup.find('table', {'id': "batting1"})
    rows = table.find_all('tr')
    output_L = []
    for items in rows[1:-1]:
        stats_L = items.text.split('\n')
        output_L.append(stats_L[1])
    return output_L

print(get_names_in_average(team_id['Chicago Dogs']))

def main(team):
    name_L2 = []
    avg_L2 = []
    for items in last_seven_avg(team):
        name_L2.append(items[0])
        avg_L2.append(items[1])
        print(items)
    split_name_L = []
    for names in name_L2:
        s = names.split(',')
        split_name_L.append(s[0])
    d = {}
    for i in range(579967, 580473):
        populate_dict(get_pbp(i), d)
    name_L = []
    avg_L = []
    for items in fps_percentage(team, d):
        split_name = items[0].split()
        print(split_name)
        if split_name[0]+ ' ' + split_name[1]=='Nick Sanchez':
            continue
        if split_name[1] in split_name_L:
            name_L.append(items[0])
            avg_L.append(items[1])
            print(items)
        if len(split_name)>2 and ((split_name[1]+' '+split_name[2]) in split_name_L):
            name_L.append(items[0])
            avg_L.append(items[1])
            print(items)
    print(name_L)
    print(split_name_L)
    print(avg_L)
    print(avg_L2)
    zipped = list(zip(get_names_in_average(team_id[team]), walk_rate(get_pa(team_id[team]), team_id[team]), k_rate(get_pa(team_id[team]), team_id[team]), iso(get_pa(team_id[team]), team_id[team])))
    sorted_zipped = sorted(zipped, key = lambda x: x[0][:3])
    walks_L = []
    strikeout_L = []
    iso_L = []
    for tups in sorted_zipped:
        if tups[0][:2] != 'x ' and tups[0]!= 'Liriano, R':
            print(tups[0])
            walks_L.append(tups[1])
            strikeout_L.append(tups[2])
            iso_L.append(tups[3])
    print(walks_L)
    print(len(walks_L))
    print(strikeout_L)
    print(len(strikeout_L))
    print(len(iso_L))
    print(iso_L)
    fp_data = {'Name': name_L, "FP Swing %": avg_L, "AVG (L7)": avg_L2, "BB%": walks_L, "K%": strikeout_L, 'ISO': iso_L}
    fp_df = pd.DataFrame(fp_data)
    print(fp_df)
    csv_name = team.split()
    fp_df.to_excel('{}.xlsx'.format(csv_name[0]+'_'+csv_name[1]+'_'+'game_day_stats'))


main('Fargo-Moorhead RedHawks')
